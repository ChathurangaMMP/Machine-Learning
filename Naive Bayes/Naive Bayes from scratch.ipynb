{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes algorithm from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naïve Bayes is a **classification** algorithm, which is based on **Bayes Theorem**. It has widely used in, \n",
    "- Spam email filtering\n",
    "- Object and face detection\n",
    "- Weather prediction\n",
    "\n",
    "There are **3 types** of this algorithm. We can choose appropriate one according to our purpose.\n",
    "- Gaussian Naïve Bayes\n",
    "- Multinomial Naïve Bayes\n",
    "- Bernoulli Naïve Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In this notebook, we have implemented the Gaussian Naïve Bayes algorithm.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code block doesn’t necessary for the algorithm. It is just to give an idea about the dataset structure.\n",
    "Its columns have following meanings.\n",
    "-\t6 – Pregnancies\n",
    "-\t148 – Glucose\n",
    "-\t72 – BloodPressure\n",
    "-\t35 – SkinThickness\n",
    "-\t0 – Insulin\n",
    "-\t33.6 – BMI\n",
    "-\t0.627 – DiabetesPedigreeFunction\n",
    "-\t50 – Age\n",
    "-\t1 - Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>6</th>\n",
       "      <th>148</th>\n",
       "      <th>72</th>\n",
       "      <th>35</th>\n",
       "      <th>0</th>\n",
       "      <th>33.6</th>\n",
       "      <th>0.627</th>\n",
       "      <th>50</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>116</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25.6</td>\n",
       "      <td>0.201</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   6  148  72  35    0  33.6  0.627  50  1\n",
       "0  1   85  66  29    0  26.6  0.351  31  0\n",
       "1  8  183  64   0    0  23.3  0.672  32  1\n",
       "2  1   89  66  23   94  28.1  0.167  21  0\n",
       "3  0  137  40  35  168  43.1  2.288  33  1\n",
       "4  5  116  74   0    0  25.6  0.201  30  0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data=pd.read_csv('datasets/pima-indians-diabetes.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following libraries will be needed throughout this notebook. So, they have imported at the beginning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import math\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we need a function to read and load the data from *csv* file. **load_csv()** function does this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_csv(filename):\n",
    "    rows=csv.reader(open(filename))\n",
    "    dataset=list(rows)\n",
    "    for i in range(len(dataset)):\n",
    "        dataset[i]=[float(x) for x in dataset[i]]\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset has to be divided into training and testing parts, according to the given ratio. This is done by randomly generated indexes. The following function helps to do this process. It returns train and test datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(dataset,split_ratio):\n",
    "    test_size=int(len(dataset)*split_ratio)\n",
    "    trainset=list(dataset)\n",
    "    testset=[]\n",
    "    while len(testset)<test_size:\n",
    "        ind=random.randrange(len(trainset))\n",
    "        testset.append(trainset.pop(ind))\n",
    "    \n",
    "    return [trainset,testset]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the dataset has to be separated by the **class**. After doing this, the dataset will be divided into **tested positive for diabetes** and **tested negative for diabetes** groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_by_class(dataset):\n",
    "    separated={}\n",
    "    for i in range(len(dataset)):\n",
    "        vector=dataset[i]\n",
    "        if vector[-1] not in separated:\n",
    "            separated[vector[-1]]=[]\n",
    "        separated[vector[-1]].append(vector)\n",
    "    \n",
    "    return separated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are using **Gaussian Probability Distribution**, we need functions to calculate **mean** and **standard deviation**. The following two functions can be used for this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean(numbers):\n",
    "    return sum(numbers)/float(len(numbers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stdev(numbers):\n",
    "    average=mean(numbers)\n",
    "    variance=sum([pow(x-average,2) for x in numbers])/float(len(numbers)-1)\n",
    "    return math.sqrt(variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize(dataset):\n",
    "    summaries=[(mean(attri),stdev(attri)) for attri in zip(*dataset)]\n",
    "    del summaries[-1]\n",
    "    return summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_by_class(dataset):\n",
    "    separated=separate_by_class(dataset)\n",
    "    summaries={}\n",
    "    for classValue,instance in separated.items():\n",
    "        summaries[classValue]=summarize(instance)\n",
    "    return summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_prob(x,mean,stdev):\n",
    "    exponent=math.exp(-(math.pow(x-mean,2)/(2*math.pow(stdev,2))))\n",
    "    return (1/(math.sqrt(2*math.pi)*stdev))*exponent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_cls_prob(summaries,inputVec):\n",
    "    probs={}\n",
    "    for classVal,classSummaries in summaries.items():\n",
    "        probs[classVal]=1\n",
    "        for i in range(len(classSummaries)):\n",
    "            mean,stdev=classSummaries[i]\n",
    "            x=inputVec[i]\n",
    "            probs[classVal]*=calc_prob(x,mean,stdev)\n",
    "    return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(summaries,inputVec):\n",
    "    probs=calc_cls_prob(summaries,inputVec)\n",
    "    best_label,best_prob=None,-1\n",
    "    for classVal,probability in probs.items():\n",
    "        if best_label is None or probability>best_prob:\n",
    "            best_prob=probability\n",
    "            best_label=classVal\n",
    "    return best_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(summaries,test_set):\n",
    "    predictions=[]\n",
    "    for i in range(len(test_set)):\n",
    "        result=predict(summaries,test_set[i])\n",
    "        predictions.append(result)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(test_set,predictions):\n",
    "    correct=0\n",
    "    for j in range(len(test_set)):\n",
    "        if test_set[j][-1]==predictions[j]:\n",
    "            correct+=1\n",
    "\n",
    "    return (correct/float(len(test_set)))*100.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split total 768 rows into train = 515 and test = 253 rows\n",
      "Accuracy: 72.33201581027669%\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    filename='datasets/pima-indians-diabetes.csv'\n",
    "    test_size=0.33\n",
    "    dataset=load_csv(filename)\n",
    "    trainset,testset=split_dataset(dataset,test_size)\n",
    "    \n",
    "    print('Split total {0} rows into train = {1} and test = {2} rows'.format(len(dataset),len(trainset),len(testset)))\n",
    "    \n",
    "    summaries=summarize_by_class(trainset)\n",
    "    predictions=get_predictions(summaries,testset)\n",
    "    accuracy=get_accuracy(testset,predictions)\n",
    "    print('Accuracy: {0}%'.format(accuracy))\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
